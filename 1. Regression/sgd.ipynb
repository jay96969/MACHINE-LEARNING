{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression With Stochastic Gradient Descent for Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# Load a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string column to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the min and max values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale dataset columns to the range 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split a dataset into k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate an algorithm using a cross validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    global coef_list\n",
    "    coef_sum = [0.0 for i in range(len(dataset[0])-1)]\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted, coef = algorithm(train_set, test_set, *args)\n",
    "        coef_sum = list(map(add, coef_sum, coef))\n",
    "        actual = [row[-1] for row in fold]\n",
    "        rmse = rmse_metric(actual, predicted)\n",
    "        scores.append(rmse)\n",
    "    coef_sum = [x / n_folds for x in coef_sum]\n",
    "    # print('******************', coef_sum)\n",
    "    coef_list.append(coef_sum)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, coefficients):\n",
    "    yhat = 0\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i] * row[i]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(row, coefficients):\n",
    "    yhat = 0\n",
    "    for i in range(len(row)):\n",
    "        yhat += coefficients[i] * row[i]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate linear regression coefficients using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    # print(\"hi`\",coef)\n",
    "    global error_list\n",
    "    for epoch in range(n_epoch):\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)\n",
    "            error = yhat - row[-1]\n",
    "            error_list.append(error)\n",
    "            coef[0] = coef[0] - l_rate * error\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
    "            # print(l_rate, n_epoch, error)\n",
    "    # print(\"hi2\",coef)\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Algorithm With Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    # global coef_list\n",
    "    coef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "    # coef_list.append(coef)\n",
    "    for row in test:\n",
    "        yhat = predict(row, coef)\n",
    "        predictions.append(yhat)\n",
    "    return predictions, coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent(A, test, l_rate = 0.25, n_epoch = 50, bsize = 10, graph = False):\n",
    "    global error_list\n",
    "    predictions = list()\n",
    "    if(bsize<1):\n",
    "        bsize=1\n",
    "    elif(bsize>A.shape[0]):\n",
    "        bsize=A.shape[0]\n",
    "    if(graph):\n",
    "        error_list = np.array([])\n",
    "    w = np.zeros(A.shape[1],1)\n",
    "    for i in range(n_epoch):   # Epochs\n",
    "        j = random.randint(0, A.shape[0]-bsize)\n",
    "        train = A[j:j+bsize,:]\n",
    "        for row in train:\n",
    "            yhat = predict(row, w)\n",
    "            error = yhat - row[-1]\n",
    "            if(graph):\n",
    "                error_list.append(error)\n",
    "            for i in range(j,j+bsize-1):\n",
    "                if(j==0):\n",
    "                    w[0] = w[0] - l_rate * error\n",
    "                else:\n",
    "                    w[i + 1] = w[i + 1] - l_rate * error * row[i]\n",
    "    for row in test:\n",
    "        yhat = predict(row, w)\n",
    "        predictions.append(yhat)\n",
    "    if(graph):\n",
    "        plt.plot(range(n_epoch, error_list))\n",
    "        plt.show()\n",
    "    return predictions, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis(dataset, deg):\n",
    "    ans = []\n",
    "    for row in dataset:\n",
    "        temp = []\n",
    "        for i in range(deg+1):\n",
    "            temp.append(row[0] ** i)\n",
    "        temp.append(row[1])\n",
    "        ans.append(temp)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moore_Penrose(A, y, lambd=0):\n",
    "        # print(\"hi\", y)\n",
    "    global mp_coef, mp_regu_coef\n",
    "    predictions = list()\n",
    "    coef = np.matmul(np.matmul(np.linalg.inv(\n",
    "        lambd*np.identity(len(A[0]))+np.matmul(A.T, A)), A.T), y)\n",
    "    if(lambd == 0):\n",
    "        mp_coef.append(coef)\n",
    "    else:\n",
    "        mp_regu_coef.append(coef)\n",
    "    for row in A:\n",
    "        yhat = predict2(row, coef)\n",
    "        predictions.append(yhat)\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(y)):\n",
    "        prediction_error = predictions[i] - y[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(y))\n",
    "    return sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "# load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Gaussian_noise.csv'\n",
    "filename20 = 'part1trial.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "# normalizefilename = 'Gaussian_noise.csv'\n",
    "# plt.scatter(dataset[0], dataset[1])\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "l_rate = 0.25\n",
    "lambd = 1e-9\n",
    "n_epoch = 50\n",
    "bsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmse = 100\n",
    "min_deg = 30\n",
    "min_rmse_batch = 100\n",
    "min_deg_batch = 30\n",
    "min_rmse_mp = 100\n",
    "min_deg_mp = 30\n",
    "min_rmse_mp_regu = 100\n",
    "min_deg_mp_regu = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = []\n",
    "rmse_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "meta_el_sgd = []\n",
    "meta_el_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_coef = []\n",
    "mp_regu_coef = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c970b4334144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0merror_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     scores_batch = evaluate_algorithm(\n\u001b[0m\u001b[0;32m     10\u001b[0m         basis_data, GradientDescent, n_folds, l_rate, n_epoch, bsize, True)\n\u001b[0;32m     11\u001b[0m     \u001b[0mmeta_el_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-e3f69bbe9414>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[1;34m(dataset, algorithm, n_folds, *args)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mrow_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mcoef_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-1a0346df670a>\u001b[0m in \u001b[0;36mGradientDescent\u001b[1;34m(A, test, l_rate, n_epoch, bsize, graph)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsize\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsize\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mbsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for n in range(1, 25):\n",
    "    basis_data = basis(dataset, n)\n",
    "    # evaluate algorithm\n",
    "    scores = evaluate_algorithm(\n",
    "        basis_data, linear_regression_sgd, n_folds, l_rate, n_epoch)\n",
    "    meta_el_sgd.append(error_list)\n",
    "    error_list = []\n",
    "    rmse = (sum(scores)/float(len(scores)))\n",
    "    scores_batch = evaluate_algorithm(\n",
    "        basis_data, GradientDescent, n_folds, l_rate, n_epoch, bsize, True)\n",
    "    meta_el_batch.append(error_list)\n",
    "    error_list = []\n",
    "    rmse_batch = (sum(scores_batch)/float(len(scores_batch)))\n",
    "    rmse_mp = Moore_Penrose(\n",
    "        np.array(basis_data)[:, :-1], np.array(basis_data)[:, -1])\n",
    "    rmse_mp_regu = Moore_Penrose(\n",
    "        np.array(basis_data)[:, :-1], np.array(basis_data)[:, -1], lambd)\n",
    "    rmse_list.append(rmse_mp_regu)\n",
    "    print('----------------Degree: %2d' % n)\n",
    "    print('Scores: %s' % scores)\n",
    "    print('Mean RMSE: %.3f' % rmse)\n",
    "    print('Mean RMSE-MP: %.3f' % rmse_mp)\n",
    "    print('Mean RMSE-MP-Regularised: %.3f' % rmse_mp_regu)\n",
    "    if(rmse < min_rmse):\n",
    "        min_rmse = rmse\n",
    "        min_deg = n\n",
    "    if(rmse_batch < min_rmse_batch):\n",
    "        min_rmse_batch = rmse_batch\n",
    "        min_deg_batch = n\n",
    "    if(rmse_mp < min_rmse_mp):\n",
    "        min_rmse_mp = rmse_mp\n",
    "        min_deg_mp = n\n",
    "    if(rmse_mp_regu < min_rmse_mp_regu):\n",
    "        min_rmse_mp_regu = rmse_mp_regu\n",
    "        min_deg_mp_regu = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*********** RESULTS ***************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Linear Regression RMSE: %.3f' % min_rmse)\n",
    "print('Min Degree: %2d' % min_deg)\n",
    "print(coef_list[min_deg-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min GD Batch RMSE: %.3f' % min_rmse_batch)\n",
    "print('Min Degree: %2d' % min_deg_batch)\n",
    "print(coef_list[min_deg_batch-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Moore-Penrose RMSE: %.3f' % min_rmse_mp)\n",
    "print('Min Degree: %2d' % min_deg_mp)\n",
    "print(mp_coef[min_deg_mp-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Moore-Penrose RMSE with Regularisation: %.3f' % min_rmse_mp_regu)\n",
    "print('Min Degree: %2d' % min_deg_mp_regu)\n",
    "print(mp_regu_coef[min_deg_mp_regu-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = np.poly1d(coef_list[min_deg-1][::-1])<br>\n",
    "x = np.arange(-20,20)<br>\n",
    "y = p(x)<br>\n",
    "# plt.plot(x, y)<br>\n",
    "# plt.scatter(dataset[0], dataset[1])<br>\n",
    "plt.plot(rmse_list)<br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rmse_list)\n",
    "plt.show()\n",
    "print(rmse_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
